# ğŸ§  Configurare NLP (Procesare de Limbaj Natural)

Acest proiect foloseÈ™te procesare de limbaj natural (NLP) pentru a Ã®nÈ›elege mai bine rÄƒspunsurile utilizatorilor È™i a oferi evaluare mai precisÄƒ È™i naturalÄƒ.

## ğŸ“¦ DependenÈ›e

Bibliotecile NLP sunt opÈ›ionale - sistemul funcÈ›ioneazÄƒ È™i fÄƒrÄƒ ele, dar cu funcÈ›ionalitÄƒÈ›i reduse.

### Instalare completÄƒ (recomandat)

```bash
# ActiveazÄƒ mediul virtual
.venv\Scripts\activate  # Windows
# sau
source .venv/bin/activate  # Linux/Mac

# InstaleazÄƒ toate dependenÈ›ele (inclusiv NLP)
# DacÄƒ ai erori SSL, foloseÈ™te:
pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org -r requirements.txt

# SAU instaleazÄƒ manual fiecare bibliotecÄƒ:
pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org sentence-transformers
pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org scikit-learn
pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org fuzzywuzzy
pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org python-Levenshtein
```

### Biblioteci NLP folosite

1. **sentence-transformers** - Similaritate semanticÄƒ Ã®ntre texte
   - Model: `paraphrase-multilingual-MiniLM-L12-v2`
   - Suport pentru romÃ¢nÄƒ È™i englezÄƒ
   - Se descarcÄƒ automat la prima utilizare (~420MB)

2. **scikit-learn** - Pentru calcularea similaritÄƒÈ›ii cosinus

3. **fuzzywuzzy** + **python-Levenshtein** - Fallback pentru matching fuzzy
   - Folosit dacÄƒ sentence-transformers nu este disponibil

## ğŸš€ FuncÈ›ionalitÄƒÈ›i NLP

### 1. Similaritate SemanticÄƒ
Sistemul poate Ã®nÈ›elege cÄƒ urmÄƒtoarele rÄƒspunsuri sunt similare semantic:
- "Backtracking" â‰ˆ "algoritm de backtracking" â‰ˆ "foloseÈ™te backtracking"
- "Echilibru Nash" â‰ˆ "Nash equilibrium" â‰ˆ "echilibru de tip Nash"

### 2. Extragere Concepte
DetecteazÄƒ concepte cheie chiar dacÄƒ sunt exprimate diferit:
- "ordine de explorare" â‰ˆ "ordinea Ã®n care exploreazÄƒ"
- "pruning" â‰ˆ "eliminare ramuri" â‰ˆ "tÄƒiere noduri"

### 3. ÃnÈ›elegere IntenÈ›ie
DetecteazÄƒ automat:
- Incertitudine: "nu sunt sigur", "poate"
- AfirmaÈ›ie: "da", "adevÄƒrat", "corect"
- Negare: "nu", "fals", "incorect"
- Justificare: "deoarece", "pentru cÄƒ"

### 4. Comparare NaturalÄƒ
ComparÄƒ rÄƒspunsuri folosind Ã®nÈ›elegere semanticÄƒ, nu doar matching exact:
- "O(b^(d/2))" â‰ˆ "complexitate O de b la puterea d pe 2"
- "minus infinit" â‰ˆ "-âˆ" â‰ˆ "negative infinity"

## âš™ï¸ Instalare rapidÄƒ

### OpÈ›iunea 1: Script automat (recomandat)
```bash
# Windows (Command Prompt)
install_nlp.bat

# Windows (PowerShell)
.\install_nlp.ps1
```

### OpÈ›iunea 2: Manual
```bash
# ActiveazÄƒ mediul virtual
.venv\Scripts\activate  # Windows

# InstaleazÄƒ dependenÈ›ele NLP
pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org sentence-transformers scikit-learn fuzzywuzzy python-Levenshtein
```

## âš™ï¸ Configurare

Sistemul detecteazÄƒ automat dacÄƒ bibliotecile NLP sunt disponibile:
- âœ… **Cu NLP**: FuncÈ›ionalitÄƒÈ›i complete, evaluare semanticÄƒ precisÄƒ
- âš ï¸ **FÄƒrÄƒ NLP**: Fallback la metode tradiÈ›ionale (regex, substring matching)

**NotÄƒ**: DacÄƒ Ã®ntÃ¢mpini erori SSL (ca `Could not find a suitable TLS CA certificate bundle`), foloseÈ™te scripturile de mai sus care includ `--trusted-host`.

## ğŸ“Š Exemple de Utilizare

### RÄƒspunsuri recunoscute ca similare:

```
Utilizator: "Algoritmul foloseÈ™te backtracking pentru a rezolva problema"
Sistem: âœ… RecunoaÈ™te "backtracking" chiar dacÄƒ nu este exact "Backtracking"

Utilizator: "Complexitatea este O de b la d pe 2"
Sistem: âœ… RecunoaÈ™te cÄƒ este echivalent cu "O(b^(d/2))"

Utilizator: "Da, deoarece algoritmul verificÄƒ sistematic toate stÄƒrile"
Sistem: âœ… SeparÄƒ rÄƒspunsul ("Da") de justificare ("deoarece...")
```

## ğŸ”§ Troubleshooting

### Eroare: "Sentence Transformers not available"
- InstaleazÄƒ: `pip install sentence-transformers scikit-learn`
- Modelul se descarcÄƒ automat la prima utilizare

### Eroare: "FuzzyWuzzy not available"
- InstaleazÄƒ: `pip install fuzzywuzzy python-Levenshtein`
- Este folosit ca fallback

### PerformanÈ›Äƒ lentÄƒ
- Prima utilizare: Modelul NLP se descarcÄƒ (~420MB)
- UtilizÄƒri ulterioare: Modelul se Ã®ncarcÄƒ Ã®n memorie (rapid)
- Pentru producÈ›ie: ConsiderÄƒ cache pentru embeddings

## ğŸ“ Note

- Modelul NLP este multilingv È™i funcÈ›ioneazÄƒ bine pentru romÃ¢nÄƒ È™i englezÄƒ
- Similaritatea semanticÄƒ este calculatÄƒ folosind embeddings (vectori de dimensiune 384)
- Pragul implicit pentru "corect" este 0.75 (75% similaritate)
- Sistemul funcÈ›ioneazÄƒ È™i fÄƒrÄƒ NLP, dar cu precizie redusÄƒ

